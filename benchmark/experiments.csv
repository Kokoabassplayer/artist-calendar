run_id,label,created_at,git_commit,temperature,model,posters,missing_predictions,judged,app_quality_score,app_quality_ci95,app_quality_ci95_low,app_quality_ci95_high,schema_strict_rate,schema_valid_rate,json_parse_rate,avg_top_level_score,avg_event_match_score,avg_event_count_score,avg_location_score,avg_venue_score,avg_missing_field_rate,avg_date_f1,prediction_cost_usd,judge_cost_usd,ground_truth_cost_usd,total_cost_usd,urls_sha256,manifest_sha256,bootstrap_seed,prompt_hashes
20260103-130449-gemma27b-ocr-refine-normalize-locfill-judge58-max,20260103-130449-gemma27b-ocr-refine-normalize-locfill-judge58-max,2026-01-03T13:04:49+00:00,c24ec64d555b28ac9101c951ef7ecda083a4f2ca,0.2,gemini-gemma-3-27b-it,58,0,58,83.75,"[81.96, 85.59]",81.96,85.59,1.0,1.0,1.0,0.738,0.736,0.986,0.744,0.667,0.294,0.748,0,0.0,2.308029,2.308029,a10ad0a4178f0cc91ae2879ca9a95b1af4ebbe9f85b75e38293ca392ec3c4265,f88643ad8231f4372cc7e36891d7b131591be31b6eec43d8eb0e2071442cff02,23,"{'benchmark/prompts/fill_locations.txt': '1bb7e46f497d55caafc4749ae18a3c2bdb0ad9d663713ec2d8dffe552bbef9ef', 'benchmark/prompts/ground_truth.txt': '5dbddf4622d452204da395ee1f5f60edc93b7e0fc55f22cb5df8951386910184', 'benchmark/prompts/interpret.txt': '7586c366b29291832b3a77a9da2643f16d0ae95ffc7137f08d2edabaa2abae16', 'benchmark/prompts/judge.txt': 'fe310d4d13ade006a81244135c3328b5c7b051a5598f3857d7042ba9102390df', 'benchmark/prompts/judge_compact.txt': '60d5d6ba913048ebdccd4e73afdf7eb7d10628cbde2d4bf8dc52710852db8863', 'benchmark/prompts/ocr.txt': '436067200b8e1802fd96a89eb0951fcd42410eb8aaaf0dca976429d48b6aba23', 'benchmark/prompts/parse_ocr.txt': '6a8d1b1f80c97a4ce6b5331d9309b2148c09184f99670bc8584a481a3ca39324', 'benchmark/prompts/parse_ocr_v2.txt': '1577ec4a9956b4cb2657a43410ab8b3824dbd7c2ace01a69b0e9f99250408b6e', 'benchmark/prompts/predict.txt': 'd01e5ce0022d1b0f993f11d290c8e8c73d2cc167d5f1035d6e5c4e6eea2ab391', 'benchmark/prompts/predict_v2.txt': '3f44d00d9d2241cccd22e44593fbd6cc760356daf7376240917ed0a52f6d9615', 'benchmark/prompts/refine_v1.txt': '3d64cb85acd7aefbc5354e6f542e469d462b42f02cedaf96aee127955e16af5f', 'benchmark/prompts/repair_json.txt': '0a570e716aece4fee3d1080dee3582edf868146a99fb8b720918e912bac8a07e'}"
20260103-130819-gemma27b-ocr-refine-normalize-locfill-timefix,20260103-130819-gemma27b-ocr-refine-normalize-locfill-timefix,2026-01-03T13:08:19+00:00,c24ec64d555b28ac9101c951ef7ecda083a4f2ca,0.2,gemini-gemma-3-27b-it,58,0,58,83.75,"[81.96, 85.59]",81.96,85.59,1.0,1.0,1.0,0.738,0.736,0.986,0.744,0.667,0.294,0.748,0,0.0,2.308029,2.308029,a10ad0a4178f0cc91ae2879ca9a95b1af4ebbe9f85b75e38293ca392ec3c4265,f88643ad8231f4372cc7e36891d7b131591be31b6eec43d8eb0e2071442cff02,23,"{'benchmark/prompts/fill_locations.txt': '1bb7e46f497d55caafc4749ae18a3c2bdb0ad9d663713ec2d8dffe552bbef9ef', 'benchmark/prompts/ground_truth.txt': '5dbddf4622d452204da395ee1f5f60edc93b7e0fc55f22cb5df8951386910184', 'benchmark/prompts/interpret.txt': '7586c366b29291832b3a77a9da2643f16d0ae95ffc7137f08d2edabaa2abae16', 'benchmark/prompts/judge.txt': 'fe310d4d13ade006a81244135c3328b5c7b051a5598f3857d7042ba9102390df', 'benchmark/prompts/judge_compact.txt': '60d5d6ba913048ebdccd4e73afdf7eb7d10628cbde2d4bf8dc52710852db8863', 'benchmark/prompts/ocr.txt': '436067200b8e1802fd96a89eb0951fcd42410eb8aaaf0dca976429d48b6aba23', 'benchmark/prompts/parse_ocr.txt': '6a8d1b1f80c97a4ce6b5331d9309b2148c09184f99670bc8584a481a3ca39324', 'benchmark/prompts/parse_ocr_v2.txt': '1577ec4a9956b4cb2657a43410ab8b3824dbd7c2ace01a69b0e9f99250408b6e', 'benchmark/prompts/predict.txt': 'd01e5ce0022d1b0f993f11d290c8e8c73d2cc167d5f1035d6e5c4e6eea2ab391', 'benchmark/prompts/predict_v2.txt': '3f44d00d9d2241cccd22e44593fbd6cc760356daf7376240917ed0a52f6d9615', 'benchmark/prompts/refine_v1.txt': '3d64cb85acd7aefbc5354e6f542e469d462b42f02cedaf96aee127955e16af5f', 'benchmark/prompts/repair_json.txt': '0a570e716aece4fee3d1080dee3582edf868146a99fb8b720918e912bac8a07e'}"
20260103-142933-20260102-114203-gemma27b-norepair-judge58-max,20260103-142933-20260102-114203-gemma27b-norepair-judge58-max,2026-01-03T14:29:33+00:00,07d0c938d60a618963c6668376ce1743d58973bf,0.2,gemini-gemma-3-27b-it,58,0,58,79.52,"[77.72, 81.46]",77.72,81.46,1.0,1.0,1.0,0.746,0.652,0.981,0.669,0.491,0.43,0.687,0,0.0,2.308029,2.308029,a10ad0a4178f0cc91ae2879ca9a95b1af4ebbe9f85b75e38293ca392ec3c4265,f88643ad8231f4372cc7e36891d7b131591be31b6eec43d8eb0e2071442cff02,23,"{'benchmark/prompts/fill_locations.txt': '1bb7e46f497d55caafc4749ae18a3c2bdb0ad9d663713ec2d8dffe552bbef9ef', 'benchmark/prompts/ground_truth.txt': '5dbddf4622d452204da395ee1f5f60edc93b7e0fc55f22cb5df8951386910184', 'benchmark/prompts/interpret.txt': '7586c366b29291832b3a77a9da2643f16d0ae95ffc7137f08d2edabaa2abae16', 'benchmark/prompts/judge.txt': 'fe310d4d13ade006a81244135c3328b5c7b051a5598f3857d7042ba9102390df', 'benchmark/prompts/judge_compact.txt': '60d5d6ba913048ebdccd4e73afdf7eb7d10628cbde2d4bf8dc52710852db8863', 'benchmark/prompts/ocr.txt': '436067200b8e1802fd96a89eb0951fcd42410eb8aaaf0dca976429d48b6aba23', 'benchmark/prompts/parse_ocr.txt': '6a8d1b1f80c97a4ce6b5331d9309b2148c09184f99670bc8584a481a3ca39324', 'benchmark/prompts/parse_ocr_v2.txt': '1577ec4a9956b4cb2657a43410ab8b3824dbd7c2ace01a69b0e9f99250408b6e', 'benchmark/prompts/predict.txt': 'd01e5ce0022d1b0f993f11d290c8e8c73d2cc167d5f1035d6e5c4e6eea2ab391', 'benchmark/prompts/predict_v2.txt': '3f44d00d9d2241cccd22e44593fbd6cc760356daf7376240917ed0a52f6d9615', 'benchmark/prompts/refine_v1.txt': '3d64cb85acd7aefbc5354e6f542e469d462b42f02cedaf96aee127955e16af5f', 'benchmark/prompts/repair_json.txt': '0a570e716aece4fee3d1080dee3582edf868146a99fb8b720918e912bac8a07e'}"
20260103-145838-20260102-123028-gemma27b-promptv2-refine-normalize-judge58-max,20260103-145838-20260102-123028-gemma27b-promptv2-refine-normalize-judge58-max,2026-01-03T14:58:38+00:00,07d0c938d60a618963c6668376ce1743d58973bf,0.2,gemini-gemma-3-27b-it,58,0,58,80.45,"[78.71, 82.26]",78.71,82.26,1.0,1.0,1.0,0.721,0.636,0.98,0.626,0.57,0.244,0.638,0,0.0,2.308029,2.308029,a10ad0a4178f0cc91ae2879ca9a95b1af4ebbe9f85b75e38293ca392ec3c4265,f88643ad8231f4372cc7e36891d7b131591be31b6eec43d8eb0e2071442cff02,23,"{'benchmark/prompts/fill_locations.txt': '1bb7e46f497d55caafc4749ae18a3c2bdb0ad9d663713ec2d8dffe552bbef9ef', 'benchmark/prompts/ground_truth.txt': '5dbddf4622d452204da395ee1f5f60edc93b7e0fc55f22cb5df8951386910184', 'benchmark/prompts/interpret.txt': '7586c366b29291832b3a77a9da2643f16d0ae95ffc7137f08d2edabaa2abae16', 'benchmark/prompts/judge.txt': 'fe310d4d13ade006a81244135c3328b5c7b051a5598f3857d7042ba9102390df', 'benchmark/prompts/judge_compact.txt': '60d5d6ba913048ebdccd4e73afdf7eb7d10628cbde2d4bf8dc52710852db8863', 'benchmark/prompts/ocr.txt': '436067200b8e1802fd96a89eb0951fcd42410eb8aaaf0dca976429d48b6aba23', 'benchmark/prompts/parse_ocr.txt': '6a8d1b1f80c97a4ce6b5331d9309b2148c09184f99670bc8584a481a3ca39324', 'benchmark/prompts/parse_ocr_v2.txt': '1577ec4a9956b4cb2657a43410ab8b3824dbd7c2ace01a69b0e9f99250408b6e', 'benchmark/prompts/predict.txt': 'd01e5ce0022d1b0f993f11d290c8e8c73d2cc167d5f1035d6e5c4e6eea2ab391', 'benchmark/prompts/predict_v2.txt': '3f44d00d9d2241cccd22e44593fbd6cc760356daf7376240917ed0a52f6d9615', 'benchmark/prompts/refine_v1.txt': '3d64cb85acd7aefbc5354e6f542e469d462b42f02cedaf96aee127955e16af5f', 'benchmark/prompts/repair_json.txt': '0a570e716aece4fee3d1080dee3582edf868146a99fb8b720918e912bac8a07e'}"
20260103-153221-20260103-141302-gemma27b-ocr-parsev2-judge58-max,20260103-153221-20260103-141302-gemma27b-ocr-parsev2-judge58-max,2026-01-03T15:32:21+00:00,07d0c938d60a618963c6668376ce1743d58973bf,0.2,gemini-gemma-3-27b-it,58,0,58,83.15,"[81.51, 84.92]",81.51,84.92,1.0,1.0,1.0,0.734,0.71,0.987,0.658,0.671,0.258,0.748,0,0.0,2.308029,2.308029,a10ad0a4178f0cc91ae2879ca9a95b1af4ebbe9f85b75e38293ca392ec3c4265,f88643ad8231f4372cc7e36891d7b131591be31b6eec43d8eb0e2071442cff02,23,"{'benchmark/prompts/fill_locations.txt': '1bb7e46f497d55caafc4749ae18a3c2bdb0ad9d663713ec2d8dffe552bbef9ef', 'benchmark/prompts/ground_truth.txt': '5dbddf4622d452204da395ee1f5f60edc93b7e0fc55f22cb5df8951386910184', 'benchmark/prompts/interpret.txt': '7586c366b29291832b3a77a9da2643f16d0ae95ffc7137f08d2edabaa2abae16', 'benchmark/prompts/judge.txt': 'fe310d4d13ade006a81244135c3328b5c7b051a5598f3857d7042ba9102390df', 'benchmark/prompts/judge_compact.txt': '60d5d6ba913048ebdccd4e73afdf7eb7d10628cbde2d4bf8dc52710852db8863', 'benchmark/prompts/ocr.txt': '436067200b8e1802fd96a89eb0951fcd42410eb8aaaf0dca976429d48b6aba23', 'benchmark/prompts/parse_ocr.txt': '6a8d1b1f80c97a4ce6b5331d9309b2148c09184f99670bc8584a481a3ca39324', 'benchmark/prompts/parse_ocr_v2.txt': '1577ec4a9956b4cb2657a43410ab8b3824dbd7c2ace01a69b0e9f99250408b6e', 'benchmark/prompts/predict.txt': 'd01e5ce0022d1b0f993f11d290c8e8c73d2cc167d5f1035d6e5c4e6eea2ab391', 'benchmark/prompts/predict_v2.txt': '3f44d00d9d2241cccd22e44593fbd6cc760356daf7376240917ed0a52f6d9615', 'benchmark/prompts/refine_v1.txt': '3d64cb85acd7aefbc5354e6f542e469d462b42f02cedaf96aee127955e16af5f', 'benchmark/prompts/repair_json.txt': '0a570e716aece4fee3d1080dee3582edf868146a99fb8b720918e912bac8a07e'}"
